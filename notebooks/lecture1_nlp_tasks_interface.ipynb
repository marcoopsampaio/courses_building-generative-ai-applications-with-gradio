{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import HTML\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())  # read local .env file\n",
    "hf_api_key = os.environ[\"HF_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API based function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "import requests, json\n",
    "\n",
    "# Summarization endpoint\n",
    "def get_completion(\n",
    "    inputs,\n",
    "    parameters=None,\n",
    "    endpoint_url=\"https://api-inference.huggingface.co/models/facebook/bart-large-cnn\",\n",
    "):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {hf_api_key}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    data = {\"inputs\": inputs}\n",
    "    if parameters is not None:\n",
    "        data.update({\"parameters\": parameters})\n",
    "    response = requests.request(\n",
    "        \"POST\", endpoint_url, headers=headers, data=json.dumps(data)\n",
    "    )\n",
    "    return json.loads(response.content.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"The tower is 324 metres (1,063 ft) tall, about the same height\n",
    "        as an 81-storey building, and the tallest structure in Paris. \n",
    "        Its base is square, measuring 125 metres (410 ft) on each side. \n",
    "        During its construction, the Eiffel Tower surpassed the Washington \n",
    "        Monument to become the tallest man-made structure in the world,\n",
    "        a title it held for 41 years until the Chrysler Building\n",
    "        in New York City was finished in 1930. It was the first structure \n",
    "        to reach a height of 300 metres. Due to the addition of a broadcasting \n",
    "        aerial at the top of the tower in 1957, it is now taller than the \n",
    "        Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the \n",
    "        Eiffel Tower is the second tallest free-standing structure in France \n",
    "        after the Millau Viaduct.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building. Its base is square, measuring 125 metres (410 ft) on each side. It is the second tallest free-standing structure in France after the Millau Viaduct.'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "get_completion = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
    "\n",
    "\n",
    "def summarize(input):\n",
    "    output = get_completion(input)\n",
    "    return output[0][\"summary_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building . It is the tallest structure in Paris and the second tallest free-standing structure in France after the Millau Viaduct . It was the first structure in the world to reach a height of 300 metres .'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://8c69e321dffe66027a.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://8c69e321dffe66027a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 142, but your input_length is only 133. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=66)\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "\n",
    "\n",
    "def summarize(input_text):\n",
    "    # Replace this with your actual function to get completion\n",
    "    output = get_completion(input_text)  # Ensure this function is defined\n",
    "    return output[0][\"summary_text\"]\n",
    "\n",
    "\n",
    "# Create the Gradio interface\n",
    "demo = gr.Interface(fn=summarize, inputs=\"text\", outputs=\"text\")\n",
    "\n",
    "# Launch the Gradio interface\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning a few details of the app\n",
    "- format the number of lines of input and output to emphasize expectations\n",
    "- add title and description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://0f7da7bff176ddfcd3.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://0f7da7bff176ddfcd3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 142, but your input_length is only 133. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=66)\n"
     ]
    }
   ],
   "source": [
    "gr.close_all()\n",
    "demo = gr.Interface(\n",
    "    fn=summarize,\n",
    "    inputs=[gr.Textbox(label=\"Text to summarize\", lines=6)],\n",
    "    outputs=[gr.Textbox(label=\"Result\", lines=3)],\n",
    "    title=\"Text summarization with distilbart-cnn\",\n",
    "    description=\"Summarize any text using the `shleifer/distilbart-cnn-12-6` model under the hood!\",\n",
    ")\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "get_completion = pipeline(\"ner\", model=\"dslim/bert-base-NER\")\n",
    "\n",
    "\n",
    "def ner(input):\n",
    "    output = get_completion(input)\n",
    "    return {\"text\": input, \"entities\": output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'B-PER',\n",
       "  'score': np.float32(0.9990625),\n",
       "  'index': 4,\n",
       "  'word': 'Andrew',\n",
       "  'start': 11,\n",
       "  'end': 17},\n",
       " {'entity': 'B-ORG',\n",
       "  'score': np.float32(0.9927857),\n",
       "  'index': 10,\n",
       "  'word': 'Deep',\n",
       "  'start': 32,\n",
       "  'end': 36},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': np.float32(0.99677867),\n",
       "  'index': 11,\n",
       "  'word': '##L',\n",
       "  'start': 36,\n",
       "  'end': 37},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': np.float32(0.9954496),\n",
       "  'index': 12,\n",
       "  'word': '##ear',\n",
       "  'start': 37,\n",
       "  'end': 40},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': np.float32(0.9959293),\n",
       "  'index': 13,\n",
       "  'word': '##ning',\n",
       "  'start': 40,\n",
       "  'end': 44},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': np.float32(0.8917463),\n",
       "  'index': 14,\n",
       "  'word': '##A',\n",
       "  'start': 44,\n",
       "  'end': 45},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': np.float32(0.5036117),\n",
       "  'index': 15,\n",
       "  'word': '##I',\n",
       "  'start': 45,\n",
       "  'end': 46},\n",
       " {'entity': 'B-LOC',\n",
       "  'score': np.float32(0.99969244),\n",
       "  'index': 20,\n",
       "  'word': 'California',\n",
       "  'start': 61,\n",
       "  'end': 71}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"My name is Andrew, I'm building DeepLearningAI and I live in California\"\n",
    "get_completion(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'B-PER',\n",
       "  'score': np.float32(0.9761178),\n",
       "  'index': 3,\n",
       "  'word': 'Julie',\n",
       "  'start': 5,\n",
       "  'end': 10},\n",
       " {'entity': 'B-ORG',\n",
       "  'score': np.float32(0.94296),\n",
       "  'index': 16,\n",
       "  'word': 'Mo',\n",
       "  'start': 71,\n",
       "  'end': 73},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': np.float32(0.5930551),\n",
       "  'index': 17,\n",
       "  'word': '##MA',\n",
       "  'start': 73,\n",
       "  'end': 75}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I am Julie. I work as an artist and recently displayed my paintings in MoMA\"\n",
    "get_completion(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.cache/pypoetry/virtualenvs/course-gradio-IFOj4Hg5-py3.11/lib/python3.11/site-packages/gradio/interface.py:415: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://8355b4121c426e9859.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://8355b4121c426e9859.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ner(input):\n",
    "    output = get_completion(input)\n",
    "    return {\"text\": input, \"entities\": output}\n",
    "\n",
    "\n",
    "gr.close_all()\n",
    "demo = gr.Interface(\n",
    "    fn=ner,\n",
    "    inputs=[gr.Textbox(label=\"Text to find entities\", lines=2)],\n",
    "    outputs=[gr.HighlightedText(label=\"Text with entities\")],\n",
    "    title=\"NER with dslim/bert-base-NER\",\n",
    "    description=\"Find entities using the `dslim/bert-base-NER` model under the hood!\",\n",
    "    allow_flagging=\"never\",\n",
    "    # Here we introduce a new tag, examples, easy to use examples for your application\n",
    "    examples=[\n",
    "        \"My name is Andrew and I live in California\",\n",
    "        \"My name is Poli and work at HuggingFace\",\n",
    "    ],\n",
    ")\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.cache/pypoetry/virtualenvs/course-gradio-IFOj4Hg5-py3.11/lib/python3.11/site-packages/gradio/interface.py:415: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://9423a6ac9e78bd57f4.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://9423a6ac9e78bd57f4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def merge_tokens(tokens):\n",
    "    merged_tokens = []\n",
    "    for token in tokens:\n",
    "        if (\n",
    "            merged_tokens\n",
    "            and token[\"entity\"].startswith(\"I-\")\n",
    "            and merged_tokens[-1][\"entity\"].endswith(token[\"entity\"][2:])\n",
    "        ):\n",
    "            # If current token continues the entity of the last one, merge them\n",
    "            last_token = merged_tokens[-1]\n",
    "            last_token[\"word\"] += token[\"word\"].replace(\"##\", \"\")\n",
    "            last_token[\"end\"] = token[\"end\"]\n",
    "            last_token[\"score\"] = (last_token[\"score\"] + token[\"score\"]) / 2\n",
    "        else:\n",
    "            # Otherwise, add the token to the list\n",
    "            merged_tokens.append(token)\n",
    "\n",
    "    return merged_tokens\n",
    "\n",
    "\n",
    "def ner(input):\n",
    "    output = get_completion(input)\n",
    "    merged_tokens = merge_tokens(output)\n",
    "    return {\"text\": input, \"entities\": merged_tokens}\n",
    "\n",
    "\n",
    "gr.close_all()\n",
    "demo = gr.Interface(\n",
    "    fn=ner,\n",
    "    inputs=[gr.Textbox(label=\"Text to find entities\", lines=2)],\n",
    "    outputs=[gr.HighlightedText(label=\"Text with entities\")],\n",
    "    title=\"NER with dslim/bert-base-NER\",\n",
    "    description=\"Find entities using the `dslim/bert-base-NER` model under the hood!\",\n",
    "    allow_flagging=\"never\",\n",
    "    examples=[\n",
    "        \"My name is Andrew, I'm building DeeplearningAI and I live in California\",\n",
    "        \"My name is Poli, I live in Vienna and work at HuggingFace\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
